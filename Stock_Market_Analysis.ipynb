{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock Market Analysis.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GWxnHoFiyeu"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "pd.set_option('display.max_columns', 100)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew\n",
        "\n",
        "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDy81CHCjh6v"
      },
      "source": [
        "df_train = pd.read_csv('boston.csv')\n",
        "print(df_train.shape)\n",
        "print(df_train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67PUm4pYjtNW"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4oREIRIjyzl"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD-bOmD9j2du"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYSzpCRkj6mm"
      },
      "source": [
        "# Split dataset into feature matrix X and target value y\n",
        "X_train = df_train.drop('INDUS', axis=1)\n",
        "y_train = df_train['INDUS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbJKUHEUkjNW"
      },
      "source": [
        "sns.displot(y_train, kde=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB-S0qs-k9y3"
      },
      "source": [
        "# Check these attributes for target's distribution\n",
        "print(\"Skewness: %f\" % y_train.skew())\n",
        "print(\"Kurtosis: %f\" % y_train.kurt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKuOTUzRlDQG"
      },
      "source": [
        "# Correlation Matrix on Heatmap\n",
        "corrmat = df_train.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corrmat, square=True, cmap='RdBu_r');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja2ztkpxlO3A"
      },
      "source": [
        "# Rank & Plot Top 9 Features Correlated with Target\n",
        "k = 10 \n",
        "cols = corrmat.nlargest(k, 'INDUS')['INDUS'].index\n",
        "cm = np.corrcoef(df_train[cols].values.T)\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.set(font_scale=1.2)\n",
        "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values, cmap='RdBu_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oboTQw7le-w"
      },
      "source": [
        "# Further, Top Correlated Features Can be Picked for Scatterplot to See if Some Linear Relations We Could Find  \n",
        "cols = ['INDUS', 'NOX', 'TAX', 'AGE', 'LSTAT', 'RAD', 'CRIM']\n",
        "sns.pairplot(df_train[cols])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptmLopKCnnRR"
      },
      "source": [
        "# First, Find & Sort NULL Values Existed in Features (Numerical)\n",
        "total = df_train.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False) # df_train.count() will count non-NA by default\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWYvrVxSn-6V"
      },
      "source": [
        "# Here, We Drop All Features with > 1 NULL Values and Drop 1 NULL Item for Electrical\n",
        "df_train = df_train.drop(missing_data[missing_data['Total'] > 1].index, 1)\n",
        "df_train = df_train.drop(df_train.loc[df_train['INDUS'].isnull()].index)\n",
        "df_train.isnull().sum().max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJXHxTt7oNdf"
      },
      "source": [
        "# We could find 2 outliers (right-bottom) are obviously out of this near-linear relation\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(X_train['CRIM'], y_train)\n",
        "plt.ylabel('INDUS', fontsize=15)\n",
        "plt.xlabel('CRIM', fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbAcHTtHtIrd"
      },
      "source": [
        "# Delete Outliers (crietrias could be obvsered and choosen, here > 4000 and < 300000)\n",
        "df_train = df_train.drop(df_train[(df_train['INDUS'] > 4000) & (df_train['CRIM'] < 300000)].index)\n",
        "\n",
        "# Plot De-Outlier Graph\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(df_train['INDUS'], df_train['CRIM'])\n",
        "plt.ylabel('CRIM', fontsize=15)\n",
        "plt.xlabel('INDUS', fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inZ8PIzmtnre"
      },
      "source": [
        "# After Plotting Distribution & Probability, skewness and peakness could be observered\n",
        "sns.distplot(df_train['CRIM'] , fit = norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train['CRIM'], plot = plt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-e6HuwXt363"
      },
      "source": [
        "# After Applying Log Transformation, Much More Fit on Normal Distribution\n",
        "df_train['CRIM'] = np.log(df_train['CRIM'])\n",
        "sns.distplot(df_train['CRIM'], fit=norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train['CRIM'], plot=plt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGwToqPYuEOV"
      },
      "source": [
        "df_train = pd.get_dummies(df_train)\n",
        "print(df_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G437WPouJdF"
      },
      "source": [
        "# Lasso Regression\n",
        "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yau95eiUuNlm"
      },
      "source": [
        "# Elastic Net Regression\n",
        "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PLwpTDtuQyF"
      },
      "source": [
        "# Kernel Ridge Regression\n",
        "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NrTaa9guVen"
      },
      "source": [
        "# Gradient Boosting Regression\n",
        "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
        "                                   max_depth=4, max_features='sqrt',\n",
        "                                   min_samples_leaf=15, min_samples_split=10, \n",
        "                                   loss='huber', random_state =5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO3ELNazuZu2"
      },
      "source": [
        "# XGBoost\n",
        "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
        "                             learning_rate=0.05, max_depth=3, \n",
        "                             min_child_weight=1.7817, n_estimators=2200,\n",
        "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
        "                             subsample=0.5213, silent=1,\n",
        "                             random_state =7, nthread = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ6dMXvcucsx"
      },
      "source": [
        "# LightGBM\n",
        "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
        "                              learning_rate=0.05, n_estimators=720,\n",
        "                              max_bin = 55, bagging_fraction = 0.8,\n",
        "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
        "                              feature_fraction_seed=9, bagging_seed=9,\n",
        "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOyJj2MNuf4t"
      },
      "source": [
        "# Define CV Score Function\n",
        "n_folds = 5\n",
        "\n",
        "def rmsle_cv(model):\n",
        "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(df_train.values)\n",
        "    rmse= np.sqrt(-cross_val_score(model, df_train.values, df_train['CRIM'].values, scoring=\"neg_mean_squared_error\", cv=kf))\n",
        "    return(rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoWQk8sFuj2P"
      },
      "source": [
        "score = rmsle_cv(lasso)\n",
        "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IOPedeAvAXA"
      },
      "source": [
        "score = rmsle_cv(ENet)\n",
        "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESGFjopEvFTX"
      },
      "source": [
        "score = rmsle_cv(KRR)\n",
        "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t4xM_WFvIev"
      },
      "source": [
        "score = rmsle_cv(GBoost)\n",
        "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTdm9BKHvTpC"
      },
      "source": [
        "score = rmsle_cv(model_xgb)\n",
        "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDDGzeGIvZzI"
      },
      "source": [
        "score = rmsle_cv(model_lgb)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeAesWSavkpO"
      },
      "source": [
        "!pip install nb2xls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlu3jEuCvoXd"
      },
      "source": [
        "df_train.to_excel('boston_file.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}